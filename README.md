üîé Retrieval-Augmented Generation (RAG) Strategies

This repository explores multiple RAG (Retrieval-Augmented Generation) strategies for document intelligence pipelines.
The project demonstrates three distinct approaches to retrieval and multilingual support, implemented in separate branches and modules.

üìå Project Overview

RAG is a powerful approach where a Large Language Model (LLM) is augmented with external knowledge sources. This repo experiments with different retrieval strategies to evaluate trade-offs in accuracy, efficiency, and multilingual adaptability.

Our focus has been on:

Hybrid retrieval combining BM25 (lexical search) with dense embeddings.
Multilingual RAG via lightweight ASCII-based language detection and translation.
Pure embedding-based retrieval using state-of-the-art sentence transformers.

We have also experimented with AWS Bedrock for managed LLM and embedding endpoints.

üöÄ Strategies Implemented

1Ô∏è‚É£ Hybrid Retrieval: BM25 + ChromaDB (with BGLatch embeddings)
Combines lexical search (BM25) with semantic embeddings (ChromaDB).
Embeddings powered by BGLatch.
Useful when exact keyword matches are important but semantic similarity adds context.
Provides strong recall + precision balance.

2Ô∏è‚É£ Multilingual Hybrid RAG
Extends the hybrid approach by handling multilingual queries.
Detects language using ASCII heuristics (fast + lightweight).
Non-English queries ‚Üí translated ‚Üí passed into the retriever.
Ensures better performance across code-mixed or non-English corpora.


## üè∑Ô∏è Branch Strategy Mapping

We maintain multiple branches to experiment with different RAG designs:

- **main** ‚Äî basic RAG for english with Hybrid Retrieval strategy
- **Multilingual-RAG-BM25-Chroma** ‚Äî hybrid retrieval combining BM25 + ChromaDB, plus ASCII-based multilingual support  
- **multilingual-RAG-Baai/bge1.5-pureChroma** ‚Äî pure embedding retrieval using BAAI BGE v1.5, with multilingual query translation

Choose the branch that aligns with your intended experiment or deployment scenario.


3Ô∏è‚É£ Pure Embedding Retrieval (BAAI BGE v1.5)
Removes BM25 and relies purely on vector embeddings.
Uses BAAI BGE v1.5 for high-quality dense representations.
Provides more semantic generalization and is better suited for multilingual and noisy input scenarios.
Evaluated against hybrid approaches for relevance and recall.
